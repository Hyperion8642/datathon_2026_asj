{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bcf50d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "import json\n",
    "from folium.plugins import HeatMap\n",
    "from shapely.geometry import MultiPoint, Point\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1795c9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Access_to_Everyday_Life_Dataset.csv')\n",
    "df.rename(columns = {'geometry/coordinates/0':'lon','geometry/coordinates/1':'lat', 'properties/attribute_id':'att_id', \n",
    "                     'properties/label_type':'label','properties/neighborhood':'neighborhood','properties/severity':'severity',\n",
    "                    'properties/is_temporary':'is_temp'},inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ec4af1",
   "metadata": {},
   "source": [
    "## Join geographic data with Everyday Life Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0605534a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          lon        lat neighborhood_accurate\n",
      "0 -122.298981  47.594616              Atlantic\n",
      "1 -122.301071  47.593357              Atlantic\n",
      "2 -122.301079  47.596844              Atlantic\n",
      "3 -122.301071  47.596500              Atlantic\n",
      "4 -122.306274  47.599930              Atlantic\n"
     ]
    }
   ],
   "source": [
    "# 2. Load the GeoJSON file\n",
    "neighborhoods_gdf = gpd.read_file('Neighborhood_Map_Atlas_Neighborhoods.geojson')\n",
    "\n",
    "# 3. Convert your DataFrame into a GeoDataFrame\n",
    "# We create a 'geometry' column using the longitude and latitude\n",
    "geometry = [Point(xy) for xy in zip(df['lon'], df['lat'])]\n",
    "incidents_gdf = gpd.GeoDataFrame(df, geometry=geometry)\n",
    "\n",
    "# Set the Coordinate Reference System (CRS)\n",
    "# GeoJSON snippet uses 'CRS84' (EPSG:4326): standard Lat/Lon\n",
    "incidents_gdf.set_crs(epsg=4326, inplace=True)\n",
    "neighborhoods_gdf.to_crs(epsg=4326, inplace=True)\n",
    "\n",
    "# 5. Perform the Spatial Join\n",
    "# This checks which neighborhood polygon each incident point \"intersects\"\n",
    "# We only bring over 'S_HOOD' (Specific Neighborhood) and 'L_HOOD' (Larger Region)\n",
    "joined_df = gpd.sjoin(\n",
    "    incidents_gdf, \n",
    "    neighborhoods_gdf[['S_HOOD', 'L_HOOD', 'geometry']], \n",
    "    how='left', \n",
    "    predicate='intersects'\n",
    ")\n",
    "\n",
    "# 6. Final Clean up\n",
    "# Rename 'S_HOOD' to 'neighborhood_accurate' and remove the geometry column if no longer needed\n",
    "joined_df = joined_df.rename(columns={'S_HOOD': 'neighborhood_accurate'})\n",
    "df_final = pd.DataFrame(joined_df.drop(columns='geometry'))\n",
    "\n",
    "print(df_final[['lon', 'lat', 'neighborhood_accurate']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b3ce562",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.drop(columns = ['type','geometry/type'],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c469d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>att_id</th>\n",
       "      <th>label</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>severity</th>\n",
       "      <th>is_temp</th>\n",
       "      <th>index_right</th>\n",
       "      <th>neighborhood_accurate</th>\n",
       "      <th>L_HOOD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.298981</td>\n",
       "      <td>47.594616</td>\n",
       "      <td>52096165</td>\n",
       "      <td>SurfaceProblem</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>Central Area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.301071</td>\n",
       "      <td>47.593357</td>\n",
       "      <td>52096166</td>\n",
       "      <td>SurfaceProblem</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>Central Area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.301079</td>\n",
       "      <td>47.596844</td>\n",
       "      <td>52096167</td>\n",
       "      <td>SurfaceProblem</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>Central Area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.301071</td>\n",
       "      <td>47.596500</td>\n",
       "      <td>52096168</td>\n",
       "      <td>SurfaceProblem</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>Central Area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.306274</td>\n",
       "      <td>47.599930</td>\n",
       "      <td>52096365</td>\n",
       "      <td>NoCurbRamp</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>Central Area</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          lon        lat    att_id           label neighborhood  severity  \\\n",
       "0 -122.298981  47.594616  52096165  SurfaceProblem     Atlantic       4.0   \n",
       "1 -122.301071  47.593357  52096166  SurfaceProblem     Atlantic       3.0   \n",
       "2 -122.301079  47.596844  52096167  SurfaceProblem     Atlantic       4.0   \n",
       "3 -122.301071  47.596500  52096168  SurfaceProblem     Atlantic       4.0   \n",
       "4 -122.306274  47.599930  52096365      NoCurbRamp     Atlantic       4.0   \n",
       "\n",
       "   is_temp  index_right neighborhood_accurate        L_HOOD  \n",
       "0    False         31.0              Atlantic  Central Area  \n",
       "1    False         31.0              Atlantic  Central Area  \n",
       "2    False         31.0              Atlantic  Central Area  \n",
       "3    False         31.0              Atlantic  Central Area  \n",
       "4    False         31.0              Atlantic  Central Area  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32caa926",
   "metadata": {},
   "outputs": [],
   "source": [
    "geometry = [Point(xy) for xy in zip(df['lon'], df['lat'])]\n",
    "gdf_incidents = gpd.GeoDataFrame(df, geometry=geometry, crs=\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c729516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Shape: (163893, 28)\n",
      "  neighborhood_accurate            NEIGH_NAME  TOTAL_POPULATION\n",
      "0              Atlantic    Council District 3          108012.0\n",
      "0              Atlantic  23rd & Union-Jackson           16724.0\n",
      "1              Atlantic    Council District 3          108012.0\n",
      "1              Atlantic  23rd & Union-Jackson           16724.0\n",
      "2              Atlantic    Council District 3          108012.0\n"
     ]
    }
   ],
   "source": [
    "# 3. Join with Official Neighborhood Atlas\n",
    "neighborhoods_atlas = gpd.read_file('Neighborhood_Map_Atlas_Neighborhoods.geojson').to_crs(\"EPSG:4326\")\n",
    "\n",
    "gdf_with_hoods = gpd.sjoin(\n",
    "    gdf_incidents, \n",
    "    neighborhoods_atlas[['S_HOOD', 'L_HOOD', 'geometry']], \n",
    "    how='left', \n",
    "    predicate='within'\n",
    ")\n",
    "\n",
    "# --- CRITICAL FIXES FOR DOUBLE JOINING ---\n",
    "# 1. Rename the neighborhood column\n",
    "gdf_with_hoods = gdf_with_hoods.rename(columns={'S_HOOD': 'neighborhood_accurate'})\n",
    "\n",
    "# 2. Drop the join index so the next sjoin doesn't conflict\n",
    "if 'index_right' in gdf_with_hoods.columns:\n",
    "    gdf_with_hoods = gdf_with_hoods.drop(columns=['index_right'])\n",
    "\n",
    "# 3. Reset the index to ensure it's clean for the next operation\n",
    "gdf_with_hoods = gdf_with_hoods.reset_index(drop=True)\n",
    "# -----------------------------------------\n",
    "\n",
    "# 4. Join with ACS Demographic Data\n",
    "url = \"https://data-seattlecitygis.opendata.arcgis.com/datasets/SeattleCityGIS::seattle-neighborhoods-top-50-american-community-survey-data.geojson\"\n",
    "acs_gdf = gpd.read_file(url)\n",
    "\n",
    "acs_cols = [\n",
    "    'NEIGH_NAME', 'TOTAL_POPULATION', 'TOTAL_HOUSEHOLDS', 'Children_under_5',\n",
    "    'Children_under_18', 'Older_Adults_65_over', 'Median_Age', 'Male', 'Female',\n",
    "    'PEOPLE_OF_COLOR_PERCENT', 'BACHELOR_HIGHER_PERCENT', 'PER_CAPITA_INCOME',\n",
    "    'RENTER_HOUSEHOLDS_PERCENT', 'DETACHED_1_UNIT_PERCENT',\n",
    "    'PUBLIC_TRANSPORTATION_PERCENT', 'POPULATION_DISABILITY_PERC',\n",
    "    'geometry'\n",
    "]\n",
    "acs_gdf_small = acs_gdf[acs_cols].to_crs(gdf_with_hoods.crs)\n",
    "\n",
    "# Perform the second spatial join\n",
    "merged_final_gdf = gpd.sjoin(\n",
    "    gdf_with_hoods,\n",
    "    acs_gdf_small,\n",
    "    how=\"left\",\n",
    "    predicate=\"within\"\n",
    ")\n",
    "\n",
    "# 5. Final Cleanup\n",
    "# If you want to keep it as a dataframe for ML models:\n",
    "df_final_clean = pd.DataFrame(merged_final_gdf.drop(columns='geometry'))\n",
    "\n",
    "print(f\"Final Shape: {df_final_clean.shape}\")\n",
    "print(df_final_clean[['neighborhood_accurate', 'NEIGH_NAME', 'TOTAL_POPULATION']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9a2c1ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>geometry/type</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>att_id</th>\n",
       "      <th>label</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>severity</th>\n",
       "      <th>is_temp</th>\n",
       "      <th>neighborhood_accurate</th>\n",
       "      <th>...</th>\n",
       "      <th>Median_Age</th>\n",
       "      <th>Male</th>\n",
       "      <th>Female</th>\n",
       "      <th>PEOPLE_OF_COLOR_PERCENT</th>\n",
       "      <th>BACHELOR_HIGHER_PERCENT</th>\n",
       "      <th>PER_CAPITA_INCOME</th>\n",
       "      <th>RENTER_HOUSEHOLDS_PERCENT</th>\n",
       "      <th>DETACHED_1_UNIT_PERCENT</th>\n",
       "      <th>PUBLIC_TRANSPORTATION_PERCENT</th>\n",
       "      <th>POPULATION_DISABILITY_PERC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Feature</td>\n",
       "      <td>Point</td>\n",
       "      <td>-122.298981</td>\n",
       "      <td>47.594616</td>\n",
       "      <td>52096165</td>\n",
       "      <td>SurfaceProblem</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>...</td>\n",
       "      <td>36.4</td>\n",
       "      <td>56878.0</td>\n",
       "      <td>51134.0</td>\n",
       "      <td>35.9</td>\n",
       "      <td>74.6</td>\n",
       "      <td>99655.0</td>\n",
       "      <td>65.7</td>\n",
       "      <td>23.6</td>\n",
       "      <td>17.1</td>\n",
       "      <td>12.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Feature</td>\n",
       "      <td>Point</td>\n",
       "      <td>-122.298981</td>\n",
       "      <td>47.594616</td>\n",
       "      <td>52096165</td>\n",
       "      <td>SurfaceProblem</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>...</td>\n",
       "      <td>36.3</td>\n",
       "      <td>8580.0</td>\n",
       "      <td>8144.0</td>\n",
       "      <td>51.7</td>\n",
       "      <td>61.9</td>\n",
       "      <td>70278.0</td>\n",
       "      <td>58.4</td>\n",
       "      <td>29.8</td>\n",
       "      <td>16.3</td>\n",
       "      <td>17.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Feature</td>\n",
       "      <td>Point</td>\n",
       "      <td>-122.301071</td>\n",
       "      <td>47.593357</td>\n",
       "      <td>52096166</td>\n",
       "      <td>SurfaceProblem</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>...</td>\n",
       "      <td>36.4</td>\n",
       "      <td>56878.0</td>\n",
       "      <td>51134.0</td>\n",
       "      <td>35.9</td>\n",
       "      <td>74.6</td>\n",
       "      <td>99655.0</td>\n",
       "      <td>65.7</td>\n",
       "      <td>23.6</td>\n",
       "      <td>17.1</td>\n",
       "      <td>12.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Feature</td>\n",
       "      <td>Point</td>\n",
       "      <td>-122.301071</td>\n",
       "      <td>47.593357</td>\n",
       "      <td>52096166</td>\n",
       "      <td>SurfaceProblem</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>...</td>\n",
       "      <td>36.3</td>\n",
       "      <td>8580.0</td>\n",
       "      <td>8144.0</td>\n",
       "      <td>51.7</td>\n",
       "      <td>61.9</td>\n",
       "      <td>70278.0</td>\n",
       "      <td>58.4</td>\n",
       "      <td>29.8</td>\n",
       "      <td>16.3</td>\n",
       "      <td>17.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Feature</td>\n",
       "      <td>Point</td>\n",
       "      <td>-122.301079</td>\n",
       "      <td>47.596844</td>\n",
       "      <td>52096167</td>\n",
       "      <td>SurfaceProblem</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>...</td>\n",
       "      <td>36.4</td>\n",
       "      <td>56878.0</td>\n",
       "      <td>51134.0</td>\n",
       "      <td>35.9</td>\n",
       "      <td>74.6</td>\n",
       "      <td>99655.0</td>\n",
       "      <td>65.7</td>\n",
       "      <td>23.6</td>\n",
       "      <td>17.1</td>\n",
       "      <td>12.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type geometry/type         lon        lat    att_id           label  \\\n",
       "0  Feature         Point -122.298981  47.594616  52096165  SurfaceProblem   \n",
       "0  Feature         Point -122.298981  47.594616  52096165  SurfaceProblem   \n",
       "1  Feature         Point -122.301071  47.593357  52096166  SurfaceProblem   \n",
       "1  Feature         Point -122.301071  47.593357  52096166  SurfaceProblem   \n",
       "2  Feature         Point -122.301079  47.596844  52096167  SurfaceProblem   \n",
       "\n",
       "  neighborhood  severity  is_temp neighborhood_accurate  ... Median_Age  \\\n",
       "0     Atlantic       4.0    False              Atlantic  ...       36.4   \n",
       "0     Atlantic       4.0    False              Atlantic  ...       36.3   \n",
       "1     Atlantic       3.0    False              Atlantic  ...       36.4   \n",
       "1     Atlantic       3.0    False              Atlantic  ...       36.3   \n",
       "2     Atlantic       4.0    False              Atlantic  ...       36.4   \n",
       "\n",
       "      Male   Female  PEOPLE_OF_COLOR_PERCENT  BACHELOR_HIGHER_PERCENT  \\\n",
       "0  56878.0  51134.0                     35.9                     74.6   \n",
       "0   8580.0   8144.0                     51.7                     61.9   \n",
       "1  56878.0  51134.0                     35.9                     74.6   \n",
       "1   8580.0   8144.0                     51.7                     61.9   \n",
       "2  56878.0  51134.0                     35.9                     74.6   \n",
       "\n",
       "   PER_CAPITA_INCOME  RENTER_HOUSEHOLDS_PERCENT  DETACHED_1_UNIT_PERCENT  \\\n",
       "0            99655.0                       65.7                     23.6   \n",
       "0            70278.0                       58.4                     29.8   \n",
       "1            99655.0                       65.7                     23.6   \n",
       "1            70278.0                       58.4                     29.8   \n",
       "2            99655.0                       65.7                     23.6   \n",
       "\n",
       "   PUBLIC_TRANSPORTATION_PERCENT  POPULATION_DISABILITY_PERC  \n",
       "0                           17.1                        12.4  \n",
       "0                           16.3                        17.2  \n",
       "1                           17.1                        12.4  \n",
       "1                           16.3                        17.2  \n",
       "2                           17.1                        12.4  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23858f80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['type', 'geometry/type', 'lon', 'lat', 'att_id', 'label',\n",
       "       'neighborhood', 'severity', 'is_temp', 'neighborhood_accurate',\n",
       "       'L_HOOD', 'index_right', 'NEIGH_NAME', 'TOTAL_POPULATION',\n",
       "       'TOTAL_HOUSEHOLDS', 'Children_under_5', 'Children_under_18',\n",
       "       'Older_Adults_65_over', 'Median_Age', 'Male', 'Female',\n",
       "       'PEOPLE_OF_COLOR_PERCENT', 'BACHELOR_HIGHER_PERCENT',\n",
       "       'PER_CAPITA_INCOME', 'RENTER_HOUSEHOLDS_PERCENT',\n",
       "       'DETACHED_1_UNIT_PERCENT', 'PUBLIC_TRANSPORTATION_PERCENT',\n",
       "       'POPULATION_DISABILITY_PERC'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1237f234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 163893 entries, 0 to 81972\n",
      "Data columns (total 28 columns):\n",
      " #   Column                         Non-Null Count   Dtype  \n",
      "---  ------                         --------------   -----  \n",
      " 0   type                           163893 non-null  object \n",
      " 1   geometry/type                  163893 non-null  object \n",
      " 2   lon                            163893 non-null  float64\n",
      " 3   lat                            163893 non-null  float64\n",
      " 4   att_id                         163893 non-null  int64  \n",
      " 5   label                          163893 non-null  object \n",
      " 6   neighborhood                   163893 non-null  object \n",
      " 7   severity                       159392 non-null  float64\n",
      " 8   is_temp                        163893 non-null  bool   \n",
      " 9   neighborhood_accurate          163840 non-null  object \n",
      " 10  L_HOOD                         163840 non-null  object \n",
      " 11  index_right                    163840 non-null  float64\n",
      " 12  NEIGH_NAME                     163840 non-null  object \n",
      " 13  TOTAL_POPULATION               162927 non-null  float64\n",
      " 14  TOTAL_HOUSEHOLDS               162927 non-null  float64\n",
      " 15  Children_under_5               162927 non-null  float64\n",
      " 16  Children_under_18              162927 non-null  float64\n",
      " 17  Older_Adults_65_over           162927 non-null  float64\n",
      " 18  Median_Age                     162927 non-null  float64\n",
      " 19  Male                           162927 non-null  float64\n",
      " 20  Female                         162927 non-null  float64\n",
      " 21  PEOPLE_OF_COLOR_PERCENT        162927 non-null  float64\n",
      " 22  BACHELOR_HIGHER_PERCENT        162927 non-null  float64\n",
      " 23  PER_CAPITA_INCOME              162927 non-null  float64\n",
      " 24  RENTER_HOUSEHOLDS_PERCENT      162927 non-null  float64\n",
      " 25  DETACHED_1_UNIT_PERCENT        162927 non-null  float64\n",
      " 26  PUBLIC_TRANSPORTATION_PERCENT  162927 non-null  float64\n",
      " 27  POPULATION_DISABILITY_PERC     162927 non-null  float64\n",
      "dtypes: bool(1), float64(19), int64(1), object(7)\n",
      "memory usage: 35.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_final_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0a87083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5001616908592802"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_final)/len(df_final_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97606a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04488294191942304"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_1 = df_final_clean[df_final_clean['neighborhood_accurate'] == df_final_clean['NEIGH_NAME']]\n",
    "len(check_1)/len(df_final_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e63e4f20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Council District 3\n",
       "0    23rd & Union-Jackson\n",
       "1      Council District 3\n",
       "1    23rd & Union-Jackson\n",
       "2      Council District 3\n",
       "Name: NEIGH_NAME, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_clean['NEIGH_NAME'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc6dc3e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Central Area\n",
       "0        Central Area\n",
       "1        Central Area\n",
       "1        Central Area\n",
       "2        Central Area\n",
       "             ...     \n",
       "81970    Central Area\n",
       "81971    Central Area\n",
       "81971    Central Area\n",
       "81972    Central Area\n",
       "81972    Central Area\n",
       "Name: L_HOOD, Length: 163893, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_clean['L_HOOD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "97dec9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/58/bxfs02q56pzfmzl9zs71htz00000gn/T/ipykernel_9298/3154352185.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_labeled['is_temp'] = df_labeled['is_temp'].astype(int)\n",
      "/var/folders/58/bxfs02q56pzfmzl9zs71htz00000gn/T/ipykernel_9298/3154352185.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_labeled.dropna(inplace = True)\n"
     ]
    }
   ],
   "source": [
    "# Drop na values\n",
    "df_labeled = df_final_clean.dropna(subset=['severity'])\n",
    "# Pre-process 'is_temp' to be 1 and 0\n",
    "df_labeled['is_temp'] = df_labeled['is_temp'].astype(int)\n",
    "features = [ 'lon', 'lat', 'att_id', 'label','is_temp', 'neighborhood_accurate', 'TOTAL_POPULATION',\n",
    "       'TOTAL_HOUSEHOLDS', 'Children_under_5', 'Children_under_18',\n",
    "       'Older_Adults_65_over', 'Median_Age', 'Male', 'Female',\n",
    "       'PEOPLE_OF_COLOR_PERCENT', 'BACHELOR_HIGHER_PERCENT',\n",
    "       'PER_CAPITA_INCOME', 'RENTER_HOUSEHOLDS_PERCENT',\n",
    "       'DETACHED_1_UNIT_PERCENT', 'PUBLIC_TRANSPORTATION_PERCENT',\n",
    "       'POPULATION_DISABILITY_PERC']\n",
    "target = 'severity'\n",
    "# Drop all remaining nas - those rows are negligible\n",
    "df_labeled.dropna(inplace = True)\n",
    "X = df_labeled[features]\n",
    "y = df_labeled[target]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "afe020ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Create a Stratification Key\n",
    "# This combines severity and neighborhood to ensure the split is proportional for both.\n",
    "# We fill NAs in categorical columns temporarily to prevent errors in concatenation.\n",
    "stratify_cols = ['severity', 'neighborhood_accurate']\n",
    "stratify_key = df_labeled[stratify_cols].astype(str).agg('-'.join, axis=1)\n",
    "\n",
    "# Handle cases where a neighborhood/severity combo appears only once \n",
    "# (Stratify requires at least 2 members per group)\n",
    "counts = stratify_key.value_counts()\n",
    "valid_indices = stratify_key.isin(counts[counts > 1].index)\n",
    "\n",
    "X_final = X[valid_indices]\n",
    "y_final = y[valid_indices]\n",
    "stratify_final = stratify_key[valid_indices] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bd5cd57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 126773\n",
      "Testing set size: 31694\n"
     ]
    }
   ],
   "source": [
    "# 4. Perform the Split (80% Train, 20% Test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_final, \n",
    "    y_final, \n",
    "    test_size=0.20, \n",
    "    random_state=42, \n",
    "    stratify=stratify_final # This keeps neighborhood and severity proportions identical\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Testing set size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "191a65a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 2. Re-run the split logic from the previous step \n",
    "# (Assuming X_train, X_test, y_train, y_test are defined as per the previous stratified split)\n",
    "\n",
    "# 3. Define the ColumnTransformer\n",
    "# This will OneHotEncode 'label' and 'neighborhood_accurate'\n",
    "# 'passthrough' means 'is_temp' will be kept as is (1s and 0s)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), ['label', 'neighborhood_accurate'])\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8ee9c20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy on Test Set: 72.06%\n"
     ]
    }
   ],
   "source": [
    "# 4. Create a Pipeline\n",
    "# A pipeline bundles the preprocessing and the model together.\n",
    "# This prevents data leakage and makes it easier to predict on new data.\n",
    "clf = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# 5. Train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 6. Evaluate\n",
    "print(f\"Model Accuracy on Test Set: {clf.score(X_test, y_test):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856582ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
